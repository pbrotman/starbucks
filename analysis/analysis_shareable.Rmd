---
title: "Starbucks Demographic Analysis"
author: "Parker Brotman"
date: '2023-03-02'
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(sf)
```

# Introduction

Welcome to my analysis of the relationship between Starbucks locations in the US and population demographics! 

In this analysis, I will first load the relevant data, then I will fit linear models to describe the number of Starbucks in a county as a function of demographic variables. 

For the sake of brevity, I will focus on only a subset of the demographic variables.

# Load data

## Starbucks data

### Load Starbucks
Convert starbucks long/lat to sf points.
```{r}
pts_starbucks <- read_csv("../data/starbucks/directory.csv") %>%
  filter(Country=="US") %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) #sets/reads format to WGS 84
```

### Load county polygons
Note: all the other files in the zip need to be included for this to work, not just the .shp -  https://stackoverflow.com/questions/61282572/cant-read-shp-file-in-r
```{r}
shape_county <- st_read("../data/census/Geography/Geographic Shape Files/cb_2018_us_county_500k.shp") %>%
  st_transform(crs = 4326)
```


### Join with geospatial data
Tally # Starbucks per county
```{r}
tbl_starbucks_per_county <- st_join(pts_starbucks, shape_county) %>%
  group_by(AFFGEOID, STATEFP, COUNTYFP) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))
```

Check: view Starbucks in MD
```{r}
ggplot(shape_county %>% filter(STATEFP=="24"))+
  geom_sf(aes())+
  geom_sf(data=tbl_starbucks_per_county %>% filter(STATEFP=="24"))
```


## Census data

While I considered a more generalized read design that reads every file in a specified folder, I opted instead to read each table individually, since ultimately, I'll need to subset the # of variables anyway.

### Define functions
```{r}
fn_load_decennial <- function(fname){
  str_c("../data/census/Decennial_2020/County Level/", fname) %>% 
    read_csv(skip = 1) %>% 
    select(-matches("^Annotation")) %>% 
    rename_with(.fn = ~str_extract(.x, "(?<=\\!\\!)[^\\!\\:]*(?=\\:?$)"), .cols = starts_with("!")) %>% # Preceded by !!, some number of non-!: characters, followed by end line or : + end 
    return()
}
```

```{r}
rename_prefix <- function(tbl, old_prefix, new_prefix){
  tbl %>% 
    rename_with(.fn = ~str_c(new_prefix, str_extract(.x, "(?<=\\!\\!)[^\\!\\:]*(?=\\:?$)")), .cols = starts_with(old_prefix)) %>% 
    return()
}
```


### Race & Hispanic/Latino
```{r}
tbl_race <- fn_load_decennial("Race (DECENNIALPL2020.P1-Data).csv") %>% 
  select(Geography:`Population of two or more races`, -`Population of one race`)

tbl_hisp_latino <- fn_load_decennial("Hispanic-Latino (DECENNIALPL2020.P2-Data).csv") %>% 
  select(Geography:`Not Hispanic or Latino`)
```


### Age & Sex

```{r}
tbl_age_sex <- read_csv("../data/census/ACS_2021/County Level/Age-Sex (ACSST5Y2021.S0101-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Total!!Total population!!AGE"), matches("^Estimate!!(Male|Female)!!Total population$")) %>% 
  rename_prefix("Estimate!!Total", "") %>% 
  rename(Male = `Estimate!!Male!!Total population`,
         Female = `Estimate!!Female!!Total population`) %>% 
  mutate(`0 to 9 years` = `Under 5 years` + `5 to 9 years`,
         `10 to 19 years` = `10 to 14 years` + `15 to 19 years`,
         `20 to 29 years` = `20 to 24 years` + `25 to 29 years`,
         `30 to 39 years` = `30 to 34 years` + `35 to 39 years`,
         `40 to 49 years` = `40 to 44 years` + `45 to 49 years`,
         `50 to 59 years` = `50 to 54 years` + `55 to 59 years`,
         `60 to 69 years` = `60 to 64 years` + `65 to 69 years`,
         `70 to 79 years` = `70 to 74 years` + `75 to 79 years`,
         `80 years and over` = `80 to 84 years` + `85 years and over`,
         .keep = "unused")
```

Side Note: This does the same as the big mutate function. If there were more columns, this could be helpful, but it is over-engineered for our use-case and less clear than the mutate.
```{r, eval=FALSE}
# https://stackoverflow.com/questions/49816669/how-to-use-map-from-purrr-with-dplyrmutate-to-create-multiple-new-columns-base
fn_combine_age <- function(tbl){
  map_dfc(c("", 1:8), ~ tbl %>%
            select(matches(str_glue("(^| ){.x}\\d "))) %>%  # select matching column pairs
            reduce(`+`)) %>%  # sum adds all values, `+` adds within column
    set_names(~map_chr(c("", 1:8), ~str_glue("{.}0 to {.}9 years"))) %>%
    rename(`80 years and over` = `80 to 89 years`) %>%
    bind_cols(select(tbl, -(`Under 5 years`:`85 years and over`)), .) %>%
    return()
}
```

### Education
```{r}
tbl_education <- read_csv("../data/census/ACS_2021/County Level/Education (ACSST5Y2021.S1501-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over")) %>% 
  rename_prefix("Estimate!!Total", "") %>% 
  select(Geography:`Graduate or professional degree`, -`Population 25 years and over`)
```

### Households
Note: relevant data only available in % of total households (create intereaction term with population to make it scale).
```{r}
tbl_household <- read_csv("../data/census/ACS_2021/County Level/Household (ACSST5Y2021.S1101-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Total!!Total Households!!UNITS IN STRUCTURE|^Estimate!!Total!!Total Households!!HOUSING TENURE")) %>% 
  rename_prefix("Estimate!!Total", "% in ")
```

### Income
Note: relevant data only available in % of total households (create intereaction term with population to make it scale).
```{r}
tbl_income <- read_csv("../data/census/ACS_2021/County Level/Income (ACSST5Y2021.S1901-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Households!!Total"), -`Estimate!!Households!!Total`) %>% 
  rename_prefix("Estimate", "% ")
```

### Industry
Can group categories further using Bureau of Labor Statistic's industry hierarchy:
https://www.bls.gov/iag/tgs/iag_index_naics.htm.
```{r}
tbl_industry <- read_csv("../data/census/ACS_2021/County Level/Industry (ACSST5Y2021.S2403-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Total!!.+$"), -matches("^Estimate!!Total!!.+!!.+!!.+$")) %>%  #only selecting one layer deep in specificity
  rename_prefix("Estimate", "") %>% 
  mutate(`Trade, transportation, and utilities` = `Wholesale trade` + `Retail trade` + `Transportation and warehousing, and utilities`, .keep="unused") %>% 
  select(Geography:Manufacturing, `Trade, transportation, and utilities`, everything())
```


### Occupation

```{r}
tbl_occupation <- read_csv("../data/census/ACS_2021/County Level/Occupation (ACSST5Y2021.S2401-Data).csv", skip = 1) %>% 
  select(Geography, `Geographic Area Name`, matches("^Estimate!!Total!!.+$"), -matches("^Estimate!!Total!!.+!!.+!!.+$")) %>%  #only selecting one layer deep in specificity
  rename_prefix("Estimate", "")
```


### Region/Division
Different source from rest of census data -- has simpler format.
```{r}
tbl_regions <- read_csv("../data/census/Geography/Regions/regions.csv")
```


## Combine data

### Combine census data
```{r}
list_tbl_census <- list(tbl_race, tbl_hisp_latino, tbl_age_sex, tbl_education, tbl_household, tbl_income, tbl_industry, tbl_occupation)

tbl_census_combined <- reduce(list_tbl_census, left_join)
```

### Combine Starbucks and census data
```{r}
tbl_all0 <- full_join(tbl_starbucks_per_county, tbl_census_combined, by=c("AFFGEOID"="Geography")) %>%
  mutate(n = replace_na(n, 0)) %>% 
  separate(`Geographic Area Name`, c("County", "State"), ", ") %>% 
  filter(State!="Puerto Rico") %>%  # May include later, but currently excluding to limit complexity
  full_join(tbl_regions, by="State") %>% 
  select(AFFGEOID:State, `State Code`:Division, everything()) %>% 
  rename_with(~str_replace_all(., " ", "_"))
```

Convert to percentages
```{r}
tbl_all <- tbl_all0 %>% 
  ungroup() %>% 
  mutate(across(!matches("^%") & !AFFGEOID:Total, ~round(./Total*100, digits=1))) %>%
  rename_with(~str_extract(., "(?<=%_in_).+$"), .cols = matches("^%_in_")) %>% 
  rename_with(~str_extract(., "(?<=%_).+$"), .cols = matches("^%_")) %>%
  mutate(Ratio = n/Total) %>% 
  select(AFFGEOID:State, State_Code:Division, Ratio, everything())
```


# Modeling
Pare down data to only modeling variables.
```{r}
tbl_modeling <- tbl_all %>%
  ungroup() %>% 
  select(-(AFFGEOID:`State_Code`), n)

attach(tbl_modeling)
```


## Basic linear model

```{r}
lm_pop <- lm(n ~ Total, data=tbl_modeling)
summary(lm_pop)
plot(n ~ Total); abline(lm_pop, col="red")
plot(lm_pop, which=c(1,2))
```


### Comments
Model: `# Starbucks ~ population`

This is our simplest model. While the $R^2$ is quite good off the bat at $.857$, we are failing to meet some of the basic regression assumptions. The basic regression assumptions are as follows:

- Linearity
- Homoscedasticity (equal variance)
- Independence
- Normality

While the relationship looks relatively *linear*, and we can assume our observations are close enough to *independent*, it is clear from that we have neither *homoscedasticity* (note how magnitude of the variance is positively correlated with fitted values in the RvF plot) nor *normality* (note how wildly the tails diverge from normality in the QQ plot).

Given the fact that we have *linearity*, but are lacking *homoscedasticity* and *normality* due to the skewed nature of both Starbucks count and population, I will attempt in my next model to remediate the violated assumptions by *log transforming* both the independent and dependent variables.


## Log transformation
```{r}
lm_pop <- lm(log1p(n) ~ log1p(Total), data=tbl_modeling)
summary(lm_pop)
plot(log1p(n) ~ log1p(Total)); abline(lm_pop, col="red")
plot(lm_pop, which=c(1,2))
```

## Log transformation and set population threshold
```{r}
tbl_modeling_thres <- tbl_modeling %>% 
  filter(Total>=50000)

attach(tbl_modeling_thres)
```

```{r}
lm_pop <- lm(log1p(n) ~ log1p(Total))  #note how much your decreasing the # of available counties
summary(lm_pop)
plot(log1p(n) ~ log1p(Total)); abline(lm_pop, col="red")
plot(lm_pop, which=c(1,2))
```

```{r}
tbl_all %>% 
  filter(Total>=50000) %>% 
  select(AFFGEOID, County, State_Code, n) %>% 
  mutate(log_pred = predict(lm_pop),
         pred = exp(log_pred)-1,
         res = resid(lm_pop)) %>% 
  arrange(desc(res))
```

```{r}
tbl_all %>% 
  filter(Total>=50000) %>% 
  select(AFFGEOID, County, State_Code, n) %>% 
  mutate(log_pred = predict(lm_pop),
         pred = exp(log_pred)-1,
         res = resid(lm_pop)) %>% 
  arrange(res)
```